{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"retail_pipeline\").getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema-on-read method is best for adhoc queries\n",
    "# dfs = spark.read.csv(\"pyspark/data/Amazon Sale Report.csv\", header=True, inferSchema=True)\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our schema explicitly\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType, DateType\n",
    "amazon_sale_report_schema = StructType([\n",
    "    StructField(\"index\", IntegerType(), True),\n",
    "    StructField(\"Order ID\", StringType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"Fulfilment\", StringType(), True),\n",
    "    StructField(\"Sales Channel\", StringType(), True),0.\n",
    "    StructField(\"Style\", StringType(), True),\n",
    "    StructField(\"SKU\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"Size\", StringType(), True),\n",
    "    StructField(\"ASIN\", StringType(), True),\n",
    "    StructField(\"Courier Status\", StringType(), True),\n",
    "    StructField(\"Qty\", IntegerType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"Amount\", DoubleType(), True),\n",
    "    StructField(\"Ship-city\", StringType(), True),\n",
    "    StructField(\"Ship-state\", StringType(), True),\n",
    "    StructField(\"Ship-postal-code\", StringType(), True),\n",
    "    StructField(\"Ship-country\", StringType(), True),\n",
    "    StructField(\"B2B\", StringType(), True),\n",
    "    StructField(\"Fulfilled-by\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Fulfilment: string (nullable = true)\n",
      " |-- Sales Channel: string (nullable = true)\n",
      " |-- Ship-Service-level: string (nullable = true)\n",
      " |-- Style: string (nullable = true)\n",
      " |-- SKU: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- ASIN: string (nullable = true)\n",
      " |-- Courier Status: string (nullable = true)\n",
      " |-- Qty: integer (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Ship-city: string (nullable = true)\n",
      " |-- Ship-state: string (nullable = true)\n",
      " |-- Ship-postal-code: string (nullable = true)\n",
      " |-- Ship-country: string (nullable = true)\n",
      " |-- B2B: string (nullable = true)\n",
      " |-- Fulfilled-by: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = spark.read.csv(\"./pyspark/data/Amazon Sale Report.csv\", header=True, schema=amazon_sale_report_schema)\n",
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------+--------------------+----------+-------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+------------+\n",
      "|index|           Order ID|    Date|              Status|Fulfilment|Sales Channel|Ship-Service-level|  Style|            SKU|     Category|Size|      ASIN|Courier Status|Qty|currency|Amount|  Ship-city| Ship-state|Ship-postal-code|Ship-country|                 B2B|Fulfilled-by|\n",
      "+-----+-------------------+--------+--------------------+----------+-------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+------------+\n",
      "|    0|405-8078784-5731545|04-30-22|           Cancelled|  Merchant|    Amazon.in|          Standard| SET389| SET389-KR-NP-S|          Set|   S|B09KXVBD7Z|          NULL|  0|     INR|647.62|     MUMBAI|MAHARASHTRA|        400081.0|          IN|                NULL|       False|\n",
      "|    1|171-9198151-1101146|04-30-22|Shipped - Deliver...|  Merchant|    Amazon.in|          Standard|JNE3781|JNE3781-KR-XXXL|        kurta| 3XL|B09K3WFS32|       Shipped|  1|     INR| 406.0|  BENGALURU|  KARNATAKA|        560085.0|          IN|Amazon PLCC Free-...|       False|\n",
      "|    2|404-0687676-7273146|04-30-22|             Shipped|    Amazon|    Amazon.in|         Expedited|JNE3371|  JNE3371-KR-XL|        kurta|  XL|B07WV4JV4D|       Shipped|  1|     INR| 329.0|NAVI MUMBAI|MAHARASHTRA|        410210.0|          IN|IN Core Free Ship...|        True|\n",
      "|    3|403-9615377-8133951|04-30-22|           Cancelled|  Merchant|    Amazon.in|          Standard|  J0341|     J0341-DR-L|Western Dress|   L|B099NRCT7B|          NULL|  0|     INR|753.33| PUDUCHERRY| PUDUCHERRY|        605008.0|          IN|                NULL|       False|\n",
      "|    4|407-1069790-7240320|04-30-22|             Shipped|    Amazon|    Amazon.in|         Expedited|JNE3671|JNE3671-TU-XXXL|          Top| 3XL|B098714BZP|       Shipped|  1|     INR| 574.0|    CHENNAI| TAMIL NADU|        600073.0|          IN|                NULL|       False|\n",
      "+-----+-------------------+--------+--------------------+----------+-------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/home/jovyan/spark-warehouse')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
